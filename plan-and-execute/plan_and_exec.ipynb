{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edfe3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY= sk-a1d5476da3ea4a169ab5c10e2b424a25\n",
      "BASE_URL= https://dashscope.aliyuncs.com/compatible-mode/v1\n",
      "MODEL_NAME= deepseek-v3.2-exp\n",
      "tavily_key= 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\n"
     ]
    }
   ],
   "source": [
    "# å‚è€ƒhttps://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/plan-and-execute/plan-and-execute.ipynb\n",
    "\n",
    "\n",
    "# ä½¿ç”¨ python-dotenv åŠ è½½ .env æ–‡ä»¶\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.messages import HumanMessage, SystemMessage\n",
    "from langchain_tavily import TavilySearch\n",
    "import os\n",
    "\n",
    "# åŠ è½½å½“å‰ç›®å½•ä¸‹çš„ .env æ–‡ä»¶\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "base_url = os.getenv(\"BASE_URL\")\n",
    "tavily_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "model_name = os.getenv(\"MODEL_NAME\")\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "\n",
    "print(\"API_KEY=\", api_key)\n",
    "print(\"BASE_URL=\", base_url)\n",
    "print(\"MODEL_NAME=\", model_name)\n",
    "print(\"tavily_key=\", tavily_key)\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = ChatOpenAI(\n",
    "    base_url=base_url,\n",
    "    model=model_name,\n",
    "    api_key=api_key,\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "user_query = \"ç°ä»»æ¾³å¤§åˆ©äºšç½‘çƒå…¬å¼€èµ›å† å†›çš„å®¶ä¹¡æ˜¯å“ªé‡Œ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c914b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Plan\n  Input should be an object [type=model_type, input_value=[{'step': 'ç¬¬ä¸€æ­¥ï¼š...åœ°ç‚¹]ä¸¾è¡Œã€‚â€™'}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     23\u001b[39m planner = model.with_structured_output(Plan)\n\u001b[32m     25\u001b[39m stream = planner.stream(\n\u001b[32m     26\u001b[39m     [\n\u001b[32m     27\u001b[39m         SystemMessage(content=plan_sys_prompt),\n\u001b[32m     28\u001b[39m         HumanMessage(content=user_query),\n\u001b[32m     29\u001b[39m     ]\n\u001b[32m     30\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# print(\"è®¡åˆ’ï¼š\", response)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3506\u001b[39m, in \u001b[36mRunnableSequence.stream\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3499\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3500\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstream\u001b[39m(\n\u001b[32m   3501\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3504\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3505\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3506\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3492\u001b[39m, in \u001b[36mRunnableSequence.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3485\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   3486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   3487\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3490\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3491\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m3492\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   3493\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3494\u001b[39m         \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   3495\u001b[39m         patch_config(config, run_name=(config \u001b[38;5;129;01mor\u001b[39;00m {}).get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name),\n\u001b[32m   3496\u001b[39m         **kwargs,\n\u001b[32m   3497\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2312\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2311\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2312\u001b[39m         chunk: Output = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2313\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m   2314\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3458\u001b[39m, in \u001b[36mRunnableSequence._transform\u001b[39m\u001b[34m(self, inputs, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   3455\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3456\u001b[39m         final_pipeline = step.transform(final_pipeline, config)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m final_pipeline\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5750\u001b[39m, in \u001b[36mRunnableBindingBase.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5743\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5744\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   5745\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5748\u001b[39m     **kwargs: Any,\n\u001b[32m   5749\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5750\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.transform(\n\u001b[32m   5751\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5752\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5753\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:4961\u001b[39m, in \u001b[36mRunnableLambda.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4953\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   4954\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   4955\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4958\u001b[39m     **kwargs: Any | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4959\u001b[39m ) -> Iterator[Output]:\n\u001b[32m   4960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4961\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_stream_with_config(\n\u001b[32m   4962\u001b[39m             \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   4963\u001b[39m             \u001b[38;5;28mself\u001b[39m._transform,\n\u001b[32m   4964\u001b[39m             ensure_config(config),\n\u001b[32m   4965\u001b[39m             **kwargs,\n\u001b[32m   4966\u001b[39m         )\n\u001b[32m   4967\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4968\u001b[39m         msg = (\n\u001b[32m   4969\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot stream a coroutine function synchronously.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4970\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUse `astream` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4971\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2312\u001b[39m, in \u001b[36mRunnable._transform_stream_with_config\u001b[39m\u001b[34m(self, inputs, transformer, config, run_type, **kwargs)\u001b[39m\n\u001b[32m   2310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2311\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2312\u001b[39m         chunk: Output = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2313\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[32m   2314\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:4900\u001b[39m, in \u001b[36mRunnableLambda._transform\u001b[39m\u001b[34m(self, chunks, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4898\u001b[39m final: Input\n\u001b[32m   4899\u001b[39m got_first_val = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# By definitions, RunnableLambdas consume all input before emitting output.\u001b[39;49;00m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If the input is not addable, then we'll assume that we can\u001b[39;49;00m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only operate on the last chunk.\u001b[39;49;00m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# So we'll iterate until we get to the last chunk!\u001b[39;49;00m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgot_first_val\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43michunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5750\u001b[39m, in \u001b[36mRunnableBindingBase.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5743\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5744\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m   5745\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5748\u001b[39m     **kwargs: Any,\n\u001b[32m   5749\u001b[39m ) -> Iterator[Output]:\n\u001b[32m-> \u001b[39m\u001b[32m5750\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.transform(\n\u001b[32m   5751\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5752\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5753\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5754\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:1552\u001b[39m, in \u001b[36mRunnable.transform\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   1549\u001b[39m             final = ichunk\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stream(final, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:536\u001b[39m, in \u001b[36mBaseChatModel.stream\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m index = -\u001b[32m1\u001b[39m\n\u001b[32m    535\u001b[39m index_type = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1275\u001b[39m, in \u001b[36mBaseChatOpenAI._stream\u001b[39m\u001b[34m(self, messages, stop, run_manager, stream_usage, **kwargs)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m   1274\u001b[39m     is_first_chunk = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:72\u001b[39m, in \u001b[36mChatCompletionStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[ChatCompletionStreamEvent[ResponseFormatT]]:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:118\u001b[39m, in \u001b[36mChatCompletionStream.__stream__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_chat_completion_chunk_weak(sse_event):\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m events_to_fire = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43msse_event\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events_to_fire:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:348\u001b[39m, in \u001b[36mChatCompletionStreamState.handle_chunk\u001b[39m\u001b[34m(self, chunk)\u001b[39m\n\u001b[32m    345\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Accumulate a new chunk into the snapshot and returns an iterable of events to yield.\"\"\"\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;28mself\u001b[39m.__current_completion_snapshot = \u001b[38;5;28mself\u001b[39m._accumulate_chunk(chunk)\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompletion_snapshot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__current_completion_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:576\u001b[39m, in \u001b[36mChatCompletionStreamState._build_events\u001b[39m\u001b[34m(self, chunk, completion_snapshot)\u001b[39m\n\u001b[32m    565\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m choice.logprobs.refusal \u001b[38;5;129;01mand\u001b[39;00m choice_snapshot.logprobs.refusal:\n\u001b[32m    566\u001b[39m             events_to_fire.append(\n\u001b[32m    567\u001b[39m                 build(\n\u001b[32m    568\u001b[39m                     LogprobsRefusalDeltaEvent,\n\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m                 ),\n\u001b[32m    573\u001b[39m             )\n\u001b[32m    575\u001b[39m     events_to_fire.extend(\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m         \u001b[43mchoice_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_done_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchoice_chunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchoice_snapshot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchoice_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_response_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    581\u001b[39m     )\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m events_to_fire\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:608\u001b[39m, in \u001b[36mChoiceEventState.get_done_events\u001b[39m\u001b[34m(self, choice_chunk, choice_snapshot, response_format)\u001b[39m\n\u001b[32m    604\u001b[39m events_to_fire: \u001b[38;5;28mlist\u001b[39m[ChatCompletionStreamEvent[ResponseFormatT]] = []\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m choice_snapshot.finish_reason:\n\u001b[32m    607\u001b[39m     events_to_fire.extend(\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_content_done_events\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoice_snapshot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchoice_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m     )\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    612\u001b[39m         \u001b[38;5;28mself\u001b[39m.__current_tool_call_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    613\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__current_tool_call_index \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._done_tool_calls\n\u001b[32m    614\u001b[39m     ):\n\u001b[32m    615\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_tool_done_event(\n\u001b[32m    616\u001b[39m             events_to_fire=events_to_fire,\n\u001b[32m    617\u001b[39m             choice_snapshot=choice_snapshot,\n\u001b[32m    618\u001b[39m             tool_index=\u001b[38;5;28mself\u001b[39m.__current_tool_call_index,\n\u001b[32m    619\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/streaming/chat/_completions.py:649\u001b[39m, in \u001b[36mChoiceEventState._content_done_events\u001b[39m\u001b[34m(self, choice_snapshot, response_format)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m choice_snapshot.message.content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._content_done:\n\u001b[32m    647\u001b[39m     \u001b[38;5;28mself\u001b[39m._content_done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m     parsed = \u001b[43mmaybe_parse_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchoice_snapshot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# update the parsed content to now use the richer `response_format`\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# as opposed to the raw JSON-parsed object as the content is now\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# complete and can be fully validated.\u001b[39;00m\n\u001b[32m    657\u001b[39m     choice_snapshot.message.parsed = parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py:199\u001b[39m, in \u001b[36mmaybe_parse_content\u001b[39m\u001b[34m(response_format, message)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmaybe_parse_content\u001b[39m(\n\u001b[32m    194\u001b[39m     *,\n\u001b[32m    195\u001b[39m     response_format: \u001b[38;5;28mtype\u001b[39m[ResponseFormatT] | ResponseFormatParam | Omit,\n\u001b[32m    196\u001b[39m     message: ChatCompletionMessage | ParsedChatCompletionMessage[\u001b[38;5;28mobject\u001b[39m],\n\u001b[32m    197\u001b[39m ) -> ResponseFormatT | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m has_rich_response_format(response_format) \u001b[38;5;129;01mand\u001b[39;00m message.content \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message.refusal:\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py:262\u001b[39m, in \u001b[36m_parse_content\u001b[39m\u001b[34m(response_format, content)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_parse_content\u001b[39m(response_format: \u001b[38;5;28mtype\u001b[39m[ResponseFormatT], content: \u001b[38;5;28mstr\u001b[39m) -> ResponseFormatT:\n\u001b[32m    261\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_basemodel_type(response_format):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseFormatT, \u001b[43mmodel_parse_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass_like_type(response_format):\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m PYDANTIC_V1:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/openai/_compat.py:171\u001b[39m, in \u001b[36mmodel_parse_json\u001b[39m\u001b[34m(model, data)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m PYDANTIC_V1:\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.parse_raw(data)  \u001b[38;5;66;03m# pyright: ignore[reportDeprecated]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/be/ai_practices/.venv/lib/python3.13/site-packages/pydantic/main.py:766\u001b[39m, in \u001b[36mBaseModel.model_validate_json\u001b[39m\u001b[34m(cls, json_data, strict, extra, context, by_alias, by_name)\u001b[39m\n\u001b[32m    760\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    761\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    762\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    763\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    764\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    767\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for Plan\n  Input should be an object [type=model_type, input_value=[{'step': 'ç¬¬ä¸€æ­¥ï¼š...åœ°ç‚¹]ä¸¾è¡Œã€‚â€™'}], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.12/v/model_type"
     ]
    }
   ],
   "source": [
    "# plan èŠ‚ç‚¹\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"æ‰§è¡Œè®¡åˆ’\"\"\"\n",
    "\n",
    "    steps: List[str] = Field(description=\"è¦éµå¾ªçš„ä¸åŒæ­¥éª¤ï¼Œåº”æŒ‰é¡ºåºæ’åˆ—\")\n",
    "\n",
    "\n",
    "plan_sys_prompt = \"\"\"é’ˆå¯¹ç»™å®šçš„ç›®æ ‡ï¼Œåˆ¶å®šä¸€ä¸ªç®€å•çš„åˆ†æ­¥è®¡åˆ’ã€‚ \n",
    "è¯¥è®¡åˆ’åº”åŒ…å«å„é¡¹å…·ä½“ä»»åŠ¡ï¼Œè‹¥æ‰§è¡Œå¾—å½“ï¼Œå°†å¾—å‡ºæ­£ç¡®ç­”æ¡ˆã€‚è¯·å‹¿æ·»åŠ ä»»ä½•å¤šä½™æ­¥éª¤ã€‚ \n",
    "æœ€åä¸€æ­¥çš„ç»“æœåº”è¯¥æ˜¯æœ€ç»ˆç­”æ¡ˆã€‚ç¡®ä¿æ¯ä¸€æ­¥éƒ½åŒ…å«äº†æ‰€æœ‰å¿…è¦çš„ä¿¡æ¯â€”â€”ä¸è¦è·³è¿‡ä»»ä½•æ­¥éª¤ã€‚\n",
    "\n",
    "ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘\n",
    "    è¾“å‡ºå¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹JSONç»“æ„ï¼š\n",
    "    {{\n",
    "        \"steps\": [\n",
    "            \"æ­¥éª¤1\",\n",
    "            \"æ­¥éª¤2\",\n",
    "            \"...\",\n",
    "            \"æœ€åä¸€æ­¥\"\n",
    "        ]\n",
    "    }}\n",
    "ç°åœ¨ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„æŸ¥è¯¢ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ã€‚\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "planner = model.with_structured_output(Plan)\n",
    "\n",
    "stream = planner.stream(\n",
    "    [\n",
    "        SystemMessage(content=plan_sys_prompt),\n",
    "        HumanMessage(content=user_query),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk, end=\"\")\n",
    "\n",
    "# print(\"è®¡åˆ’ï¼š\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢è¿™ä¸¤ä¸ªé—®é¢˜ã€‚å…³äºå¤©æ°”ä¿¡æ¯æˆ‘å¯ä»¥é€šè¿‡å·¥å…·è·å–ï¼Œä½†è‹±é›„è”ç›ŸS15æ€»å†³èµ›çš„ä¿¡æ¯éœ€è¦æœç´¢æ¥ç¡®è®¤ã€‚ä¸Šæµ·çš„å¤©æ°”æ˜¯æ™´æœ—ï¼Œæ¸©åº¦25æ‘„æ°åº¦ã€‚{\"query\": \"2025å¹´è‹±é›„è”ç›ŸS15æ€»å†³èµ› ä½ç½® ä¸»åŠ›åœºåœ°\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.sohu.com/a/917592239_122464149\", \"title\": \"2025è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›ï¼ˆS15ï¼‰ï¼šèµ›ç¨‹å…¬å¸ƒã€åœºé¦†å®‰æ’ - æœç‹\", \"content\": \"2025è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›(S15)å°†äº10æœˆ14æ—¥è‡³11æœˆ9æ—¥åœ¨ä¸­å›½åŒ—äº¬ã€ä¸Šæµ·ã€æˆéƒ½ä¸‰åœ°ä¸¾è¡Œï¼Œè¿™æ˜¯ç»§2017å¹´å’Œ2020å¹´åï¼Œè¯¥é¡¹é¡¶çº§ç”µç«èµ›äº‹ç¬¬ä¸‰æ¬¡åœ¨ä¸­å›½ä¸¾åŠã€‚èµ›äº‹æ€»\", \"score\": 0.86767644, \"raw_content\": null}, {\"url\": \"https://ol.3dmgame.com/gl/312865.html\", \"title\": \"LOLS15å…¨çƒæ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ä¸€è§ˆ_3DMç½‘æ¸¸\", \"content\": \"* ä¸»ç«™ * å•†åŸ * è®ºå› * è‡ªè¿è¥ ç™»å½•;) æ³¨å†Œ;) * é¦–é¡µ * å•æœº * æ‰‹æ¸¸ * è½¯ä»¶ * ç½‘æ¸¸ * è‡ªè¿è¥ * å•†åŸ * æ–°é—» * ç”µç« * è¯„æµ‹ * è§†é¢‘ * æ”»ç•¥ æ‚¨çš„ä½ç½®ï¼šç½‘æ¸¸ >  *å›¾æ–‡æ”»ç•¥*  > LOLS15å…¨çƒæ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ä¸€è§ˆ # LOLS15å…¨çƒæ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ä¸€è§ˆ ### LOLS15å…¨çƒæ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ä¸€è§ˆ å…¥å›´èµ›ä¸ç‘å£«è½®é˜¶æ®µ â€“ åŒ—äº¬æ™ºæ…§ç”µç«èµ›äº‹ä¸­å¿ƒ æ·˜æ±°èµ›é˜¶æ®µ â€“ ä¸Šæµ·æ¢…èµ›å¾·æ–¯-å¥”é©°æ–‡åŒ–ä¸­å¿ƒ å† äºšå†›å†³èµ› â€“ æˆéƒ½ä¸œå®‰æ¹–ä½“è‚²å…¬å›­å¤šåŠŸèƒ½ä½“è‚²é¦† æ›´å¤š2025å…¨çƒæ€»å†³èµ›ç›¸å…³å†…å®¹ï¼Œæ•¬è¯·å…³æ³¨å¾®åš@è‹±é›„è”ç›Ÿèµ›äº‹ï¼Œèµ›äº‹å®˜ç½‘ lpl.qq.com LOLS15å…¨çƒæ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ä¸€è§ˆ æ³¨å†Œ;) * é­”å…½ä¸–ç•Œæ—¶å…‰æœ å…¬æµ‹ æš‚æ—  09-23 * å¤©é¾™å…«éƒ¨Â·å½’æ¥ å…¬æµ‹ é¢†å– 07-25 * å¤©é¾™å…«éƒ¨Â·å½’æ¥ é™å·æµ‹è¯• æš‚æ—  04-18 * è¯›ä»™ä¸–ç•Œ åŒè¡Œæµ‹è¯• æš‚æ—  12-29 * ã€ŠLOLã€‹2025å…¨çƒæ€»å†³èµ›11æœˆ9æ—¥T1 VS KTæ¯”èµ›è§†é¢‘ * ã€ŠLOLã€‹2025å…¨çƒæ€»å†³èµ›11æœˆ2æ—¥T1 VS TESæ¯”èµ›è§†é¢‘ * ã€ŠLOLã€‹2025å…¨çƒæ€»å†³èµ›11æœˆ1æ—¥GEN VS KTæ¯”èµ›è§†é¢‘ * ã€ŠLOLã€‹2025å…¨çƒæ€»å†³èµ›10æœˆ31æ—¥AL VS T1æ¯”èµ›è§†é¢‘ * å¼€å§‹æ¸¸æˆ è¿›å…¥å®˜ç½‘ * å¼€å§‹æ¸¸æˆ è¿›å…¥å®˜ç½‘ * å®‰å“ä¸‹è½½ è¿›å…¥å®˜ç½‘ * å®‰å“ä¸‹è½½ è¿›å…¥å®˜ç½‘ * å®‰å“ä¸‹è½½ è¿›å…¥å®˜ç½‘ * å¼€å§‹æ¸¸æˆ è¿›å…¥å®˜ç½‘ * å¼€å§‹æ¸¸æˆ è¿›å…¥å®˜ç½‘ * å¼€å§‹æ¸¸æˆ è¿›å…¥å®˜ç½‘ äº¬ICPå¤‡14006952å·-1 äº¬B2-20201630 Â Â äº¬ç½‘æ–‡ï¼ˆ2019ï¼‰3652-335å· æ²ªå…¬ç½‘å®‰å¤‡ 31011202006753å·æœªæˆå¹´äººä¸¾æŠ¥ï¼šlegal@3dmgame.com\", \"score\": 0.8266142, \"raw_content\": null}, {\"url\": \"https://www.dealmoon.com/guide/1003087\", \"title\": \"å®˜å®£äº†ï¼2025è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›S15è½åœ°ä¸­å›½ï¼ - Dealmoon\", \"content\": \"* é¦–é¡µ * ç‚¹å‡»æ’è¡Œ çœé’±å›  5595 æµè§ˆ ### 2017å¹´ä¸¾åŠåœ°ä¸åœºé¦† **2020å¹´ä¸¾åŠåœ°ä¸åœºé¦†**ï¼šä¸Šæµ·ã€‚ çœé’±å› * è¶…å…¨æ±‡æ€»ï¼æŒç»­æ›´æ–°2026ç¾å›½æ¼”å”±ä¼šç»ˆææŒ‡å—ğŸ”¥æ±ªè‹æ³·/è¿›å‡»çš„å·¨äºº/TWICE/é™¶å–†/è¾¹ä¼¯è´¤ * è¾¹ä¼¯è´¤ 2026ç¾å›½å·¡æ¼”æ‹‰æ–¯ç»´åŠ æ–¯ç«™ã€ŒREVERIEã€é‡ç£…å®˜å®£ï¼æ—¶é—´/åœ°ç‚¹/è´­ç¥¨ä¿¡æ¯ çœé’±å› *21* 1823 lululemon é»‘äº”ï¼šAmazon é»‘äº”å¤§ä¿ƒå¼€æŠ¢å•¦ è¯„è®ºæŠ½ç¤¼å¡ 1220 Amazon é»‘äº”ï¼šLa Mer é¦–é€æ­£è£…å¥‡è¿¹æ™šéœœ+ä¿®å¤å”‡èœœ 1å¹´1åº¦ğŸ”¥7.5æŠ˜èµ·+7é‡å¥½ç¤¼ 1584 La Mer Lancome é»‘äº”å¼€æŠ¢ æ¢è´­ç¤¼åŒ…æ— é—¨æ§› 182 Lancome é»‘äº”ï¼šKiehl's å‡çº§å…¨åœº6.5æŠ˜ åŒç“¶æ­£è£…é«˜ä¿æ¹¿å¥—è£…4.5æŠ˜ 91 Kiehl's Elemisé™ä»Šæ—¥7.5æŠ˜ | çº¯ç¾Šç»’poloè¡«$29 åŒ—é¢å¤§é‡ä¸Šæ–° ç¾½ç»’æœ$133 264 Alo Yoga Uniqlo æ¥æŠ¥æ©äº† é»‘äº”å¤§ä¿ƒå¼€å¯ 5938 Uniqlo é»‘äº”ï¼šå…¨å‘˜å…¥åœº | Nordstrom Rack æ¸…ä»“å¤§ä¿ƒ é¢å¤–6æŠ˜ 32 Nordstrom Rack é»‘äº”ï¼šShiseido å¤§ä¿ƒå¼€å¯ï½œè¯„è®ºåŒºæŠ½å¥–èµ¢çº¢è…°å­ 3.6æŠ˜èµ·+9ä»¶è±ªç¤¼(å«æ­£è£…) * lululemon Groove Nulu é«˜è…°å–‡å­è£¤ å¸¸è§„æ¬¾ * lululemon Align Palazzoé˜”è…¿é•¿è£¤ * lululemon Wunder Puff çŸ­æ¬¾ç¾½ç»’é©¬ç”² 600è“¬æ¾åº¦ * lululemon Wunder Train é«˜è…°å£è¢‹ç´§èº«è£¤ 25è‹±å¯¸ * lululemon Always Down ç¾½ç»’æœ * lululemon Softstreme é«˜è…°é•¿è£¤ å¸¸è§„æ¬¾ * lululemon Swift å®½è…¿ä¸­è…°é•¿è£¤ * lululemon Align Palazzo å®½æ¾é•¿è£¤ * è¶…å…¨æ±‡æ€»ï¼æŒç»­æ›´æ–°2026ç¾å›½æ¼”å”±ä¼šç»ˆææŒ‡å—ğŸ”¥æ±ªè‹æ³·/è¿›å‡»çš„å·¨äºº/TWICE/é™¶å–†/è¾¹ä¼¯è´¤ dreamç”Ÿæ´»è®° 7 çœé’±å› 17 å²è¿ªä»”çš„å°é¸­ 12 AAAä¸“ä¸šæ‘¸é±¼ 6 amazon $6.99 ribeyeğŸ¥©æ„Ÿæ©èŠ‚å¤§é¤è¿™ä¸å°±æœ‰å•¦ï¼\", \"score\": 0.73138535, \"raw_content\": null}, {\"url\": \"https://2025lolworlds.com/page_4.html\", \"title\": \"2025è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›å®˜æ–¹ç½‘ç«™- ä¸¾åŠåœ°ä¸èµ›ç¨‹å…¨å…¬å¼€_ç¬¬4é¡µ\", \"content\": \"ç”±äºé˜Ÿé•¿å¡ç“¦å“ˆå°”å› è†éƒ¨æ‰‹æœ¯é•¿æœŸç¼ºé˜µï¼Œé˜¿è¯ºå¾·å°†æ‰¿æ‹…èµ·å³åå«ä¸»åŠ›èŒè´£ã€‚å°½ç®¡è´¹å¾·Â·å·´å°”éŸ¦å¾·è¿‘æœŸå®¢ä¸²è¯¥ä½ç½®ï¼Œä½†æ®ã€Šé˜¿æ–¯æŠ¥ã€‹é€éœ²ï¼Œä¸»å¸…å“ˆç»´Â·é˜¿éš†ç´¢æ›´å€¾å‘\", \"score\": 0.63397753, \"raw_content\": null}, {\"url\": \"https://news.qq.com/rain/a/20250725A02NH100\", \"title\": \"è‹±é›„è”ç›ŸS15å…¨çƒæ€»å†³èµ›èµ›ç¨‹æ—¶é—´ä¸ä¸¾åŠåŸå¸‚åœºé¦†å…¬å¸ƒï¼ - è…¾è®¯æ–°é—»\", \"content\": \"å…¥å›´èµ›ä¸ç‘å£«è½®10æœˆ14æ—¥è‡³25æ—¥ï¼šåŒ—äº¬æ™ºæ…§ç”µç«èµ›äº‹ä¸­å¿ƒ Â· æ·˜æ±°èµ›10æœˆ28æ—¥è‡³11æœˆ2æ—¥ï¼šä¸Šæµ·æ¢…èµ›å¾·æ–¯-å¥”é©°æ–‡åŒ–ä¸­å¿ƒ Â· æ€»å†³èµ›11æœˆ9æ—¥ï¼šæˆéƒ½ä¸œå®‰æ¹–ä½“è‚²å…¬å›­å¤šåŠŸèƒ½\", \"score\": 0.59796065, \"raw_content\": null}], \"response_time\": 0.93, \"request_id\": \"afc181c1-b161-448d-9709-61cfe671192a\"}æ ¹æ®æŸ¥è¯¢ç»“æœï¼Œæˆ‘ä¸ºæ‚¨æ•´ç†äº†ç›¸å…³ä¿¡æ¯ï¼š\n",
      "\n",
      "**ä»Šå¤©ä¸Šæµ·çš„å¤©æ°”ï¼š**\n",
      "- **å¤©æ°”çŠ¶å†µï¼š** æ™´æœ—\n",
      "- **æ¸©åº¦ï¼š** 25æ‘„æ°åº¦\n",
      "\n",
      "**2025å¹´è‹±é›„è”ç›ŸS15æ€»å†³èµ›ä¸¾åŠåœ°ç‚¹ï¼š**\n",
      "\n",
      "2025å¹´è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›ï¼ˆS15ï¼‰å°†åœ¨ä¸­å›½å¤šä¸ªåŸå¸‚ä¸¾è¡Œï¼Œå…·ä½“åœºé¦†å®‰æ’å¦‚ä¸‹ï¼š\n",
      "\n",
      "- **å…¥å›´èµ›ä¸ç‘å£«è½®é˜¶æ®µï¼ˆ10æœˆ14æ—¥è‡³25æ—¥ï¼‰ï¼š** åŒ—äº¬æ™ºæ…§ç”µç«èµ›äº‹ä¸­å¿ƒ\n",
      "- **æ·˜æ±°èµ›é˜¶æ®µï¼ˆ10æœˆ28æ—¥è‡³11æœˆ2æ—¥ï¼‰ï¼š** ä¸Šæµ·æ¢…èµ›å¾·æ–¯-å¥”é©°æ–‡åŒ–ä¸­å¿ƒ\n",
      "- **å† äºšå†›å†³èµ›ï¼ˆ11æœˆ9æ—¥ï¼‰ï¼š** æˆéƒ½ä¸œå®‰æ¹–ä½“è‚²å…¬å›­å¤šåŠŸèƒ½ä½“è‚²é¦†\n",
      "\n",
      "è¿™æ˜¯è‹±é›„è”ç›Ÿå…¨çƒæ€»å†³èµ›ç»§2017å¹´å’Œ2020å¹´åï¼Œç¬¬ä¸‰æ¬¡åœ¨ä¸­å›½ä¸¾åŠã€‚æ•´ä¸ªèµ›äº‹å°†æŒç»­è¿‘ä¸€ä¸ªæœˆæ—¶é—´ï¼Œä»10æœˆ14æ—¥åˆ°11æœˆ9æ—¥ã€‚"
     ]
    }
   ],
   "source": [
    "# åˆå§‹åŒ– Tavily æœç´¢å·¥å…·\n",
    "tavily_search = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    ")\n",
    "\n",
    "# å¤©æ°”å·¥å…·\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯\n",
    "    Args:\n",
    "        city (str): åŸå¸‚åç§°\n",
    "    \"\"\"\n",
    "    # è¿™é‡Œå¯ä»¥é›†æˆå®é™…çš„å¤©æ°”APIè°ƒç”¨\n",
    "    return f\"{city}çš„å¤©æ°”æ˜¯æ™´æœ—ï¼Œæ¸©åº¦25æ‘„æ°åº¦ã€‚\"\n",
    "\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "react_agent = create_agent(\n",
    "    tools=[tavily_search, get_weather],\n",
    "    model=model,\n",
    "    # system_prompt=\"You are a helpful research assistant. Use web search to find accurate, up-to-date information.\",\n",
    ")\n",
    "\n",
    "# user_query = \"å»ç½‘ä¸ŠæŸ¥ä¸€ä¸‹2025å¹´è‹±é›„è”ç›ŸS15æ€»å†³èµ›åœ¨å“ªé‡Œä¸¾åŠï¼Ÿ\"\n",
    "\n",
    "\n",
    "for token, metadata in react_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_query}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    # print(token)\n",
    "    # print(\"\\n\")\n",
    "    content = token.content\n",
    "    if content:\n",
    "        print(content, end=\"\")\n",
    "    # elif chunk.tool_calls:\n",
    "    #     print(f\"Calling tools: {[tc['name'] for tc in latest_message.tool_calls]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c53bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-practices",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
